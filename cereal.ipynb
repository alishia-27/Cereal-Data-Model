{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Cm49N4hQg0N9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c65d680-97d6-4223-e2a5-52614895732e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Metrics: MSE = 37.00, RMSE = 6.08, MAE = 5.12, R2 = 0.83\n",
            "SVM Metrics: MSE = 191.51, RMSE = 13.84, MAE = 11.35, R2 = 0.13\n",
            "Gradient Boosting Metrics: MSE = 25.50, RMSE = 5.05, MAE = 3.89, R2 = 0.88\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Loading the dataset\n",
        "file_path = 'cereal.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Dropping the 'name' and 'mfr' columns as they are not needed for the analysis\n",
        "data.drop(['name', 'mfr'], axis=1, inplace=True)\n",
        "\n",
        "# Converting the 'type' column to binary values: 0 for 'C' and 1 for 'H'\n",
        "data['type'] = data['type'].apply(lambda x: 0 if x == 'C' else 1)\n",
        "\n",
        "# Defining the feature variables and the target variable\n",
        "X = data.drop('rating', axis=1)  # Feature variables\n",
        "y = data['rating']  # Target variable\n",
        "\n",
        "# Splitting the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initializing the models\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "svm_model = SVR()\n",
        "gb_model = GradientBoostingRegressor(random_state=42)\n",
        "\n",
        "# Training the models\n",
        "rf_model.fit(X_train, y_train)\n",
        "svm_model.fit(X_train, y_train)\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions\n",
        "rf_predictions = rf_model.predict(X_test)\n",
        "svm_predictions = svm_model.predict(X_test)\n",
        "gb_predictions = gb_model.predict(X_test)\n",
        "\n",
        "# Defining a function to calculate metrics\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return mse, rmse, mae, r2\n",
        "\n",
        "# Calculate metrics for each model\n",
        "rf_mse, rf_rmse, rf_mae, rf_r2 = calculate_metrics(y_test, rf_predictions)\n",
        "svm_mse, svm_rmse, svm_mae, svm_r2 = calculate_metrics(y_test, svm_predictions)\n",
        "gb_mse, gb_rmse, gb_mae, gb_r2 = calculate_metrics(y_test, gb_predictions)\n",
        "\n",
        "# Print the metrics\n",
        "print(\"Random Forest Metrics: MSE = {:.2f}, RMSE = {:.2f}, MAE = {:.2f}, R2 = {:.2f}\".format(rf_mse, rf_rmse, rf_mae, rf_r2))\n",
        "print(\"SVM Metrics: MSE = {:.2f}, RMSE = {:.2f}, MAE = {:.2f}, R2 = {:.2f}\".format(svm_mse, svm_rmse, svm_mae, svm_r2))\n",
        "print(\"Gradient Boosting Metrics: MSE = {:.2f}, RMSE = {:.2f}, MAE = {:.2f}, R2 = {:.2f}\".format(gb_mse, gb_rmse, gb_mae, gb_r2))"
      ]
    }
  ]
}